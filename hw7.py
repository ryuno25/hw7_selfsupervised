# -*- coding: utf-8 -*-
"""hw7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X1aL8X425Pkhc7sJ7w-6g58_e7Sye-5r
"""

!pip install transformers datasets evaluate openai accelerate

import torch
from torch.utils.data import DataLoader
from transformers import AutoTokenizer
from torch.utils.data import DataLoader
from datasets import load_dataset
import evaluate as evaluate
from transformers import get_scheduler
from transformers import AutoModelForSequenceClassification
import argparse
import subprocess
import os
import openai
import requests
import time
def openAI(model, prompt):
    openai.api_key = ""

    response = openai.Completion.create(
        model=model,
        prompt=prompt,
        temperature=0.5,
        max_tokens=1,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0
    )

    return response

def get_n_samples(dataset_train, n = 8):
  passages = list(dataset_train['passage'])
  questions = list(dataset_train['question'])
  answers = list(dataset_train['answer'])
  listOfPassages = []
  listOfQuestions = []
  listOfAnswers = []
  previousAnswer = True
  i = 0
  Prompt = ""
  while len(listOfAnswers) < n:
    if answers[i] != previousAnswer:
      listOfPassages.append(passages[i])
      listOfQuestions.append(questions[i])
      listOfAnswers.append(answers[i])
      Prompt += "Passage: " + passages[i] + "\n"
      Prompt += "Question: " + questions[i] + "\n"
      Prompt += str(answers[i]) + "\n"
      Prompt += "\n"
      previousAnswer = answers[i]
    i += 1
  return Prompt, listOfPassages, listOfQuestions, listOfAnswers

def q4():
    dataset = load_dataset("boolq")
    dataset = dataset.shuffle()["train"]
    
    dataset_train_subset = dataset[5000:5030]
    longPrompt, listOfPassages, listOfQuestions, listOfAnswers = get_n_samples(dataset, 8)
    numCorrect = 0

    passages = list(dataset_train_subset['passage'])
    questions = list(dataset_train_subset['question'])
    answers = list(dataset_train_subset['answer'])
    for i in range(30):
        prompt = longPrompt + "Passage: " + passages[i] + "\n" + "Question: " + questions[i] + "\n"
        completion = openAI("davinci", prompt)
        print(completion["choices"][0]["text"])
        print(str(answers[i]))

        if str(completion["choices"][0]["text"]) == str(answers[i]):
            numCorrect += 1

    print("\nCorrectly Labelled:", numCorrect)
    print("Accuracy:", numCorrect / 30)

def query(API_URL,payload):
  headers = {"Authorization": f"Bearer "}
  response = requests.post(API_URL, headers=headers, json=payload)
  return response.json()
  
def q5():
  API_URL = "https://api-inference.huggingface.co/models/bigscience/bloomz"
  dataset = load_dataset("boolq")
  dataset = dataset.shuffle()["train"]
  dataset_train_subset = dataset[5000:]

  longPrompt, listOfPassages, listOfQuestions, listOfAnswers = get_n_samples(dataset, 4) # error when input is 1000 tokens+
  numCorrect = 0
  passages = list(dataset_train_subset['passage'])
  questions = list(dataset_train_subset['question'])
  answers = list(dataset_train_subset['answer'])
  numCorrect = 0
  num_done = 0
  i = 0
  print(longPrompt)
  while num_done != 100:
    prompt = longPrompt + "Passage: " + passages[i] + "\n" + "Question: " + questions[i] + "\n"
    num_done += 1
    output = query(API_URL, {
      "inputs": prompt
    })
    completion = output[0]["generated_text"].split()[-1]
    print("Completion:", completion)
    print("Answer:", str(answers[i]))
    if completion == str(answers[i]):
      numCorrect += 1
    i += 1
  print("\n")
  print("\nCorrectly Labelled:", numCorrect)
  print("Accuracy:", numCorrect / 100)

def q6():
  API_URL = "https://api-inference.huggingface.co/models/bigscience/bloom-petals"
  dataset = load_dataset("boolq")
  dataset = dataset.shuffle()["train"]
  dataset_train_subset = dataset[5000:]

  longPrompt, listOfPassages, listOfQuestions, listOfAnswers = get_n_samples(dataset, 4) # error when input is 1000 tokens+
  numCorrect = 0
  passages = list(dataset_train_subset['passage'])
  questions = list(dataset_train_subset['question'])
  answers = list(dataset_train_subset['answer'])
  numCorrect = 0
  num_done = 0
  i = 0
  while num_done != 100:
    prompt = longPrompt + "Passage: " + passages[i] + "\n" + "Question: " + questions[i] + "\n"
    num_done += 1
    output = query(API_URL, {
        "inputs": prompt, "wait_for_model": True
    })
    print(output)
    completion = output[0]["generated_text"].split()[-1]
    print("Completion:", completion)
    print("Answer:", str(answers[i]))
    if completion == str(answers[i]):
      numCorrect += 1
    i += 1
  print("\n")
  print("\nCorrectly Labelled:", numCorrect)
  print("Accuracy:", numCorrect / 100)

q4()

q5()

q6()

